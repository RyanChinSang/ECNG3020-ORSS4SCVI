NOTE: All dates are in the format: dd.mm.yyyy
________________________________________________________________________________________________________________________
dev0.1{a,b,c} (17.09.2017 - 08.11.2017)
(17.19.2017)------------------------------------------------------------------------------------------------------------
tldr; Able to read-in from Webcam and do some basic processing on the live video feed using OpenCV v3.3.0.10
1. Setup coding environment using:
   a. PyCharm 2017.2.3
   b. Python 3.6.3 64-bit
2. Added initial test code which adapted closely to the Python tutorials done by Harrison Kinsley.
   REF: https://pythonprogramming.net/loading-images-python-opencv-tutorial/
3. Structured basic project directories for coding; BETA, Base, Stable, History etc.
4. Made GitHub repository as version control, history, and backup of all code
   REF: https://github.com/RyanChinSang/ECNG3020-ORSS4SCVI
(18.09.2017)------------------------------------------------------------------------------------------------------------
tldr; More OpenCV tutorials
1. Added more Test Code/Tutorial; able to do color filtering and edge detection on live video feed
2. Added some documents relevant to the tutorial topic in-folder.
(04.10.2017)------------------------------------------------------------------------------------------------------------
tldr; Investigation into the Google TensorFlow Object Detection Application Programming Interface (GTFODAPI)
1. Download and Setup Google TensorFlow (GTF) in project (https://www.tensorflow.org/install/install_windows) and
   (https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md)
   a. Installed TensorFlow python v1.3.0 using PyCharm
   b. Looked at TensorFlow Model Zoo (https://github.com/tensorflow/models)
      i. The "pre-trained detection models on the COCO dataset (http://cocodataset.org/#home)
         A. The "TF detection model zoo":
            https://github.com/tensorflow/models/blob/477ed41e7e4e8a8443bc633846eb01e2182dc68a/object_detection/g3doc/
            detection_model_zoo.md
   c. GTF Object detection API (https://github.com/tensorflow/models/tree/master/research/object_detection)
   d. Followed the GFT ODAPI's example:
      (https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb)
   e. Followed a working, built example by Dat Tran for Python 3:
      Article/blog: https://towardsdatascience.com/building-a-real-time-object-recognition-app-with-tensorflow-and-
                    opencv-b7a2b4ebdc32
      Git-repo: https://github.com/datitran/object_detector_app
      i. Pulled Dat Tran's object_dector_app, examined how it worked in relation to Google's example for the Object
         Detection API in 1.d.
         A. Inspected the layout of "object_detection_app.py" in relation to the sample code given in 1.d.
         B. Noted the differences and attempted to understand why what worked, works and was necessary.
     ii. "object_detection_app.py" ran correctly without errors performing object detection and recognition/
         classification as it should.
    iii. Noted the involvement of a "protobuf" process  that was outlined by both Dat Tran and the GTFODAPI's documents
         that was not used to make Dat Tran's example code work.
(06.10.2017)------------------------------------------------------------------------------------------------------------
tldr;
1. Worked on an OpenCV implementation of a color filter; working from BRG (OpenCV default) colorspace into a HSV colors
   space.
   a. Implemented using sliders to control the lower (0) and upper (255) bound of the H, S and V components
   b. Tested around using the sliders to get best values for Green, Red and Blue color extraction
2.
(12.10.2017)------------------------------------------------------------------------------------------------------------
tldr;
1. Worked on OpenCV implementations of Gradients.
   a. LaPlacian
   b. Sobel
   c. Scharr
   d. Made notes and reference links to all of the above.
2. Worked on OpenCV implementations of Morphological transformations
   a. Looked at the effects of:
      i. Dilation
     ii. Erosion
    iii. Opening
     iv. Closing
      v. Morphological Gradients
     vi. Top-hat
    vii. Black-hat
   b. Compared, read and made notes on all the above methods
3. Worked on OpenCV implementations of Blurs:
   a. Averaging
   b. Gaussian
   c. Median
   d. Bilateral
   e. Made notes and references to all of the above.
4. Worked on more ColourFilter implementations:
   a. Tried having the sliders correspond to the R, G, B colourspace; min and max.
   NB1: The HSV implementation works better, but is less intuitive.
(16.10.2017)------------------------------------------------------------------------------------------------------------
tldr;
1. Worked on OpenCV implementation of GrabCutForegroundExtraction:
   NB1: Although code was successfully made, and runs, this module was completed without further reading for deeper
        understanding or appreciation for this type of image processing.
2. Worked on OpenCV implementation of Template Matching:
   a. Used "rpoPort.jpg" as the template to match against the occurrences of a cluster of pixels that have a similar
      footprint to it in the image "rpiStack.jpg"
   NB1: The method is fairly effective, however the accuracy of the detections is greatly dependent on the quality of
        the template in the first place.
3. Worked on an OpenCV implementation of Feature matching.
   a. Takes two reference images "fmimg.jpg" and "fmtemp.jpg" and matches similar features using a straight line.
   NB1: Although code was successfully made, and runs, this module was completed without further reading for deeper
        understanding or appreciation for this type of image processing.
   NB2: This made use of ORB, and orb.detectAndCompute
4. Worked on an OpenCV implementation of MOG2 Background Extraction
   a. Added references for further reading and deeper understanding
   NB1: Although code was successfully made, and runs, this module was completed without further reading for deeper
        understanding or appreciation for this type of image processing.
5. Worked on an OpenCV implementation of MOG2
   a. Added references for further reading and deeper understanding
   NB1: Although code was successfully made, and runs, this module was completed without further reading for deeper
        understanding or appreciation for this type of image processing.
6. Downloaded freely available, and public haarcascades for eyes and head.
   a. Looked at how Haar cascades work
   b. Looked at how Haar cascades is implemented in Python
(23.10.2017)------------------------------------------------------------------------------------------------------------
tldr;
1. Made a Haar cascade file "TUT-HaarCasObjDet.py".
   a. Made an App file stemming from the original, working code to detect when an eye is close to being closed or closed
      and to then sound an alarm/Beep.
   b. Code does not run fluidly as the Beep natively calls a sleep routine. Could be alleviated by using Threading.
(25.10.2017)------------------------------------------------------------------------------------------------------------
tldr;
1. Improved on the APP file created by implementing threading to handle the processing required for making the alarm/
   beep.
2. Made an app scanner using OpenCV for any object with 4 edges.
   a. Detects from VideoCapture any object that had 4 distinguishable points.
   b. Get the contour of the boundary defined by those 4 points
   c. Uses a perspective transform (more reading necessary)
   d. Then uses a warp Perspective (more reading necessary)
   e. Passes warped image through a Gaussian adaptive threshold
   f. returns a flat image of the contoured (outlined) object in the VideoCapture frame(s)
3.
(26.10.2017)------------------------------------------------------------------------------------------------------------
tldr;
1. Revised making
(27.10.2017)------------------------------------------------------------------------------------------------------------
ocv
(31.10.2017)------------------------------------------------------------------------------------------------------------
tldr; explored Speech to Text, Text to Speech and more progress on ColorID
1. Looked at how Speech Recognition (Speech to Text, or stt, or s2t) could be accomplished in Python
   (specifically a Python 3-compatible method)
   a. Immediate reference to a Python library "SpeechRecognition" (v3.7.1)
      https://pypi.python.org/pypi/SpeechRecognition/
      i. Uses a variety of Speech Recognition APIs (SRAPIs)
     ii. Offers both Online and Offline SRAPIs
   b. Looked into using Online Speech Recognition provided by this top-layer python library and the services it calls on
      to relay data to Google Cloud Speech API.
      NB1: More research is necessary here.
      NB2: For future implementations, testing for which online service would be best used may be necessary.
   c. Looked into using Offline Speech Recognition provided by this top-layer python library and the backend library
      named CMU Sphinx (pocketsphinx)
      i. Computationally intensive, fairly less accurate than Google's Speech Recognition
     ii. Noticeably slower.
      NB1: The existance of using this as the Offline SR would be questioned at a later stage.
      NB2: GTF has it's own Speech Recognition implementation. More research is needed.
2. Installed pocketshinx, and have Python's SpeechRecognition use that backend correctly.
3. Some testing was carried out with sample code and examples to explore the functionality of the library
4. Looked at how Text to Speech (or tts or t2s) could be accomplished in Python
   (specifically a Python 3-compatible method)
   a. Immediate reference to a Python libraries:
      i. pyttsx3: https://github.com/nateshmbhat/pyttsx3
     ii. gTTS: https://github.com/pndurette/gTTS
   b. gTTS is online and returns results in an audio-file, which then needs to be played-back to be effective.
   c. pttsx3 is offline and uses the computer's native OS speech engine to invoke the speech audio without having to be
      played-back using heavy-overhead processes. (https://pythonprogramminglanguage.com/text-to-speech/)
   d. Looked at some example code for pyttsx3 and gTTS.
      i. Able to Change Rate of Speech
     ii. Able to Change Voice of Speach
    iii. Able to Change Volume
     iv. Able to invoke an interrupt on new request for tts instances
5. Attempt to make ColorID algorithm that works fairly accurately to take RGB value into a name
   i. REF: https://stackoverflow.com/questions/34366981/python-pil-finding-nearest-color-rounding-colors
           https://stackoverflow.com/questions/9694165/convert-rgb-color-to-english-color-name-like-green
(01.11.2017)------------------------------------------------------------------------------------------------------------
(02.11.2017)------------------------------------------------------------------------------------------------------------
(03.11.2017)------------------------------------------------------------------------------------------------------------
(05.11.2017)------------------------------------------------------------------------------------------------------------
(07.11.2017)------------------------------------------------------------------------------------------------------------
(08.11.2017)------------------------------------------------------------------------------------------------------------

________________________________________________________________________________________________________________________
Stable v0.1a release (08.11.2017)

________________________________________________________________________________________________________________________
Stable v0.1b release (09.11.2017)


________________________________________________________________________________________________________________________
dev0.2a (10.11.2017 - 30.11.2017)
(11.11.2017)------------------------------------------------------------------------------------------------------------
tldr; Documentation and clean-up
1. Renamed "ORSSv02-a.py" to "ORSSd02-a.py" to reflect that the file is intended as a developmental version.
2. Tidy up README.md and added more information in VERSION.txt and TODO.txt.
(15.11.2017)------------------------------------------------------------------------------------------------------------
tldr; FPS support in VideoStream, more documentation, progress for dev0.2a
1. Added native fps support for VideoStream
   1- Added new functions fps() and avg_fps() for displaying the current fps, and average fps respectively
      a. Added import numpy library
      b. Added initialization for class variables:
         i. self.freq
        ii. self.s
            A. is initialized as 0 so as to ensure the first value is very small REF: FPS CASE A
               I. This ensures that the average fps is not out-of-whack for the first few seconds of runtime due to a large
                  number causing  inaccurate fps averages for that time.
            B. is updated with every read() call
       iii. self.avg
      NB1: For FPS CASE B, the first and last values of fps() are significantly lower when the loop starts and ends
           (pressing 'q') respectively.
      NB2: #1.b.ii.A.I. is only the case when avg_fps() or fps() is called before the first read() in the local loop
   2- Cleaned up some redundant language in config() (matches what was coded for resize())
   NB1: This is a non-conformance to cv2.VideoCapture()
2. Modified referencing convention slightly in TODO.txt
   a. Notes (NB) are now part of the string chain
   b. All NB's must be numbered, starting at 1
3. Removed the (done) tag in TODO.txt
   a. Replace the old tag by a specific [COMPLETED] section of the document
4. Added [DESCRIPTION] section of the document, and an [INFORMATION] section also in TODO.txt
5. Synchronized the dating format for VERSION.txt and TODO.txt
6. dev0.2a prototype conformed to the updated VideoStream for conveniently showing the current fps
7. Attempted to make a matplotlib imshow (does NOT work) in it's own file (class)
8. Attempted to make custom list of colors for colorID functionality
   a. Need to find a quicker way to traverse a dictionary
   b. Need to find a quicker way to convert a string array into an integer array
   NB1: Old default method is quicker.
9. Attempted making Offline operation (partially works)
   a. Needs further testing with an active internet connection
   b. Global state of internet not implemented
   c. Logic of online and offline operation needs to be thought out further
10. Looked at some string optimizations:
    REF: https://stackoverflow.com/questions/1316887/what-is-the-most-efficient-string-concatenation-method-in-python
         https://www.python.org/dev/peps/pep-0498/
11. Added a method of benchmarking various implementations of the avg_color() function for ColorID
(16.11.2017)------------------------------------------------------------------------------------------------------------
tldr;
1. Added a benchmark folder, with a benchmarking template.
2. Added full Python2 support for VideoStream
3. Adopted a convention to using single quotations (apostrophes) to define strings
(17.11.2017)------------------------------------------------------------------------------------------------------------
tldr;
1. Added the ability to get the number of available cameras, and correctly ID each camera
   a. Is a windows-specific port method for invoking DirectShow C++ APIs for enumerating capture devices on OpenCV's
      backend.
(30.11.2017)------------------------------------------------------------------------------------------------------------
tldr; Offline/Online mode, improved ColourID, improved code structure, minor speed-ups, fixed minor bugs
1. Updated VideoStream to iterate 10 indexes (0 to 9) and create a list of operational video sources (sources that
   return .isOpened())
   a. If more than one video feed is found operational, it uses the first detected index as the video source
   NB1: This does NOT associate a device name to the detected index.
2. Uses a quicker (than default) method to traverse the local dictionary of known colors in RGB format
   (REF: 15.11.2017 #8.a.)
   NB1: This new way is some 20% faster than original method
3. New dictionary "controls_dict" that lists all the manual controls for the whole application.
   a. This replaces the keymap. loop for mpl's rcParams
   b. Is much more formatted output
   c. Includes custom controls to be printed out, in the correct (manually) alphabetical order
4. Made all event.key() values correspond to the first configured key as outlined by "controls_dict" for the
   key_press_handler() function's logic
   a. This avoids having to define keys twice and ensures compatibility
5. Overhauled how offline/online operation is handled - "state"; True = online, False = offline
   a. Uses a global boolean variable "state" that initializes on internet()'s output during configure()'s routine
   b. Regardless of Online or Offline, pressing 'z', refreshes "state" on internet()
   c. Regardless of Online or Offline, pressing 'x', will force Offline operation *(no s2t operation)
   d. PocketSphinx is no longer used (may revert, or make configurable)
6. Fixed RGB and BGR mix-up for the new avg_color() closest-match computation
7. Implemented 'faster' string writing (REF: 15.11.2017 #10) for writing fps to frame
8. Used Queues to share data between Threads
   a. This allowed the functions to be put into it's own model file. This enhances the structure and organization of the
      the overall code
   b. Each model can be looked at specifically as those files scopes the associated function(s) and/or variables
   NB1: This saved about 150 line in the main ORSS-file
9. Added Gaussian blur and then averaging blur as pre-processing to the ColorID process
   a. This reduces the impact of noise on the pixel in the region of interest and therefore gives a more accurate result
   b. The size of kernels for both filters are adjustable with variable 's' in "ColorID.py"
10. Added new feature that sets the default save directory for screenshots.
   a. Screenshots will no longer save in the Windows user folder. It will instead now save in a dedicated folder named
      'Screenshots' in the root directory of the script.
   b. If the 'Screenshots' directory has been deleted or renamed for some reason, the code will create a new directory
      properly named as 'Screenshots' - it therefore also detects if the folder did exist first
   NB1: All directories should transition according to the root folder and is therefore flexible

________________________________________________________________________________________________________________________
Stable v0.2a release (01.12.2017)

________________________________________________________________________________________________________________________
dev0.3a (01.12.2017 - ??.??.????)
(16.12.2017)------------------------------------------------------------------------------------------------------------
tldr; Screenshots now save at correct resolution, improved naming
1. Fixed screenshots saving at incorrect resolution
   a. This was accomplished by manually resizing the original screenshot using the PIL library
      NB1: This is actually "treating the symptoms" instead of "finding the cure"
2. Renamed "SpchRecg.py" model to "Spch2Txt.py" to keep consistent naming w.r.t. the already named "Txt2Spch.py" model.
3. Investigated the possibility of a "Loading Screen"